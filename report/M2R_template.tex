\documentclass[a4paper,11pt, titlepage]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[a4paper,top=1in,bottom=1in,left=1in,right=1in,marginparwidth=1.75cm]{geometry}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{afterpage}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{listings}
\lstset{
    frame = single, 
    framexleftmargin=15pt
}
\usepackage{caption}
\captionsetup[figure]{labelfont={bf},labelsep=quad}
\usepackage[ruled,vlined]{algorithm2e}
\makeatletter
\renewcommand{\SetKwInOut}[2]{%
  \sbox\algocf@inoutbox{\KwSty{#2}\algocf@typo:}%
  \expandafter\ifx\csname InOutSizeDefined\endcsname\relax% if first time used
    \newcommand\InOutSizeDefined{}\setlength{\inoutsize}{\wd\algocf@inoutbox}%
    \sbox\algocf@inoutbox{\parbox[t]{\inoutsize}{\KwSty{#2}\algocf@typo:\hfill}~}\setlength{\inoutindent}{\wd\algocf@inoutbox}%
  \else% else keep the larger dimension
    \ifdim\wd\algocf@inoutbox>\inoutsize%
    \setlength{\inoutsize}{\wd\algocf@inoutbox}%
    \sbox\algocf@inoutbox{\parbox[t]{\inoutsize}{\KwSty{#2}\algocf@typo:\hfill}~}\setlength{\inoutindent}{\wd\algocf@inoutbox}%
    \fi%
  \fi% the dimension of the box is now defined.
  \algocf@newcommand{#1}[1]{%
    \ifthenelse{\boolean{algocf@inoutnumbered}}{\relax}{\everypar={\relax}}%
%     {\let\\\algocf@newinout\hangindent=\wd\algocf@inoutbox\hangafter=1\parbox[t]{\inoutsize}{\KwSty{#2}\algocf@typo\hfill:}~##1\par}%
    {\let\\\algocf@newinout\hangindent=\inoutindent\hangafter=1\parbox[t]{\inoutsize}{\KwSty{#2}\algocf@typo:\hfill}~##1\par}%
    \algocf@linesnumbered% reset the numbering of the lines
  }}%
\makeatother
\usepackage{bm}
\usepackage[normalem]{ulem}
\setlength{\marginparwidth}{2cm}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\renewcommand*{\rmdefault}{bch}
\renewcommand*{\ttdefault}{lmtt}
\newcommand{\citationneeded}{\textcolor{red}{[citation-needed]}}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}
\setlength{\parskip}{0.5em}
\usepackage[numbers, comma, square, sort&compress]{natbib}
\bibliographystyle{abbrvunsrtnat.bst}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newcommand{\reporttitle}{Scientific Machine Learning: Neural Ordinary and Control Differential Equations}
\newcommand{\reportauthorA}{James Tay (CID: 02015786)}
\newcommand{\reportauthorB}{Jiaru (Eric) Li (CID: 02216531)}
\newcommand{\reportauthorC}{Student name 3 (CID: -------------)}
\newcommand{\reportauthorD}{Student name 4 (CID: -------------)}
\newcommand{\reportauthorE}{Student name 5 (CID: -------------)}
\newcommand{\supervisor}{Sheehan Olver}
\begin{document}
\begin{titlepage}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\includegraphics[width=8cm]{figures/Imperial_logo.png}\\[1cm]
\center
\textsc{\LARGE Imperial College London}\\[0.5cm] 
\textsc{\Large Department of Mathematics}\\[1.5cm] 
\textsc{\Large Second-year Group Research Project}\\[0.5cm]
\makeatletter
\HRule \\[0.6cm]
{\huge \bfseries \reporttitle}\\[0.6cm]
\HRule \\[1.5cm]
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
\reportauthorA \\
\reportauthorB \\
\reportauthorC \\
\reportauthorD \\
\reportauthorE
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor(s):} \\
\supervisor
\end{flushright}
\end{minipage}\\[2cm]
\makeatother
\vfill
\makeatletter
{\large \today}\\[2cm]
\makeatother
\end{titlepage}
\begin{abstract}
\textcolor{red}{Type your abstract here. The abstract is a summary of the contents of the project. It should be brief but informative, and
should avoid technicalities as far as possible.}
\end{abstract}
\tableofcontents
\clearpage

\section{Introduction}
\label{sec:introduction}

\textcolor{red}{The introduction should attempt to set your work in the context of other work done in the field. It
should demonstrate that you are aware of what you are doing, and how it relates to other work
(with references). It should also provide an overview of the contents of the project. You should
highlight your individual contributions and any novel result: which of the calculations, theorems,
examples, proofs, conjectures, codes etc. are your own?}

\section{Neural Networks}

\subsection{History and Introduction}

Before diving into neural ordinary and control differential equations, we shall first explore the field of \textit{neural network}. Generally speaking, a neural network is a group of units called \textit{neurons} connected by signals called \textit{synapses}.

Back in 1943, Warren McCulloch and Walter Pitts published a seminal paper \cite{McCulloch1943}, in which they proposed the first mathematical model of an \textit{artificial neural network}, inspired by biological neural networks in animal brains. This model was named the McCulloch–Pitts neuron, or \textit{perceptron}. In some sense, it could ‘learn’ from given data and make decisions or predictions based on some parameters. The process of optimising the choice of such parameters is called \textit{training} the neural network.

Later in 1958, Frank Rosenblatt described an implementation of perceptron in detail \cite{Rosenblatt1958}. The field of neural network expanded quickly, and nowadays, it is extensively used in various fields such as machine learning and artificial intelligence. We shall explore some simple applications later.

\subsection{Basic Concepts}

\subsubsection{Structure}

A neural network (abbreviated NN) consists of interconnected neurons, each of which can be thought as a mathematical function. They are typically organised into \textit{layers} consisting of

\begin{itemize}
    \item an \textit{input layer} that receives the data,
    \item multiple \textit{hidden layers} that processes the data, and
    \item an \textit{output layer} that produces the result.
\end{itemize}

The input and output data are usually given as real numbers. The whole neural network can therefore be thought as a function $f:\mathbb{R}^m\rightarrow\mathbb{R}^n$ that takes an input vector $\mathbf{x}$ of dimension $m$ and an output vector $\mathbf{y}$ of dimension $n$.

The ultimate purpose of training a neural network is to minimise the error between the predicted output $\mathbf{y}$ and targeted output $\mathbf{\hat{y}}$, usually given as a \textit{loss function} $L(\mathbf{y}, \mathbf{\hat{y}})$. Each connection between neurons has a \textit{weight}, and possibly a \textit{bias}, which are adjusted in the process of training, allowing the model to generalise to unseen data. They are usually given altogether as a \textit{weight matrix} $\mathbf{W}$ and a \textit{bias vector} $\mathbf{b}$.

\subsubsection{Activation Function}

For neural networks with multiple layers, an \textit{activation function} $\sigma$ is usually used. This is because it helps to decide whether a neuron should be ‘activated’ and introduces non-linearity into the model. The output of each neuron in a layer is therefore computed as $\mathbf{z}^l=\sigma\left(\mathbf{W}^l\mathbf{z}^{l-1}+\mathbf{b}^l\right)$, where $\sigma$ acts element-wise, $\mathbf{z}^l$ is the output vector for layer $l$, $\mathbf{W}^l$ is the weight matrix connecting layer $l-1$ to layer $l$, and $\mathbf{b}^l$ is the bias vector for layer $l$. 

As for the choice of the activation function, the S-shaped \textit{sigmoid function} has some nice properties: it is bounded, differentiable with a non-negative derivative, and has exactly one point of inflection. Two familiar examples of sigmoid functions are the \textit{logistic function} $\sigma(x)=1/\left(1+e^{-x}\right)$ and the hyperbolic tangent function $\sigma(x)=\tanh x$. Another commonly used activation function is the \textit{rectifier}, or \textit{rectified linear unit} (ReLU), defined as $\sigma(x)=\max(0, x)$.

\begin{figure}[htbp]
    \centering
    \begin{minipage}{0.32\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                title={$1/\left(1+e^{-x}\right)$},
                xlabel={$x$},
                ylabel={$y$},
                grid=major,
                width=\textwidth,
                height=0.75\textwidth,
                xmin=-5, xmax=5,
                ymin=-0.1, ymax=1.1,
            ]
                \addplot[blue, thick, samples=200] {1 / (1 + exp(-x))};
            \end{axis}
        \end{tikzpicture}
    \end{minipage}%
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                title={$\tanh(x)$},
                xlabel={$x$},
                ylabel={$y$},
                grid=major,
                width=\textwidth,
                height=0.75\textwidth,
                xmin=-5, xmax=5,
                ymin=-1.1, ymax=1.1,
            ]
                \addplot[red, thick, samples=200] {tanh(x)};
            \end{axis}
        \end{tikzpicture}
    \end{minipage}%
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                title={$\max(0,x)$},
                xlabel={$x$},
                ylabel={$y$},
                grid=major,
                width=\textwidth,
                height=0.75\textwidth,
                xmin=-5, xmax=5,
                ymin=-1, ymax=5,
            ]
                \addplot[green, thick, samples=200, domain=-5:5] {max(0,x)};
            \end{axis}
        \end{tikzpicture}
    \end{minipage}
    \centering
    \caption{Three activation functions.}
\end{figure}

\subsubsection{Types}

\textit{Feedforward neural networks} (FNN) and \textit{recurrent neural networks} (RNN) are two main categories of neural networks. So far, we have been discussing FNN only, whose flow of information is uni-directional, from the input layer to the output layer, without any cycles or loops. FNN is sufficient for ordinary tasks such as regression and classification. However, for more complicated problems, RNN plays an important role. In RNN, outputs from previous steps can be fed as input to the current step, allowing it to maintain a form of ‘memory’. This makes RNN particularly effective for tasks such as time series prediction, natural language processing, and speech recognition. We will delve into RNN more deeply later.

\subsubsection{Gradient Descent and Backpropagation}

\textit{Gradient descent} is an algorithm that helps to find the local minima of a function. Intuitively speaking, it starts at a given point and proceeds to the opposite direction of the gradient, where the function descends the most, then continues until the gradient vanishes, which is the local minimum. In the context of neural network, it is used to minimise the loss function. During the process of calculating the gradients with respect to the parameters, another algorithm called \textit{backpropagation} (backward propagation of errors) is typically used. It operates by ‘propagating’ the error from the output layer back through the network and calculating the gradients by the chain rule. We will discuss these two concepts in more detail later.

\subsection{Example: Regression}
points to cover:
\begin{itemize}
    \item theory
    \item Lux.jl
    \item an implementation
\end{itemize}

\subsection{Example: Number Classification}
points to cover:
\begin{itemize}
    \item theory
    \item Flux.jl
    \item an implementation
\end{itemize}

\section{Introduction to Neural ODEs/CDEs}

\section{Solving Neural ODEs/CDEs}

\subsection{Solving Steps}

Solving differential equations is a difficult process, requiring much effort in existence theorems and techniques. Solving neural ODEs and NCDEs therefore poses a significant challenge in and of itself. Having defined basic neural network and neural ODEs/CDEs theory, we now turn our attention to the steps required to solve such problems numerically.

Consider \textcolor{red}{need to edit this based on the formal definition of the neural ODEs/CDEs we define, likely in an earlier section} a neural ODE defined by neural networks $f$ and $g$, such that $f_\theta$, when provided with parameters $\theta$, defines the differential equation of the system $\dot{x} = f_\theta\left(t, x\right)$, and $g_\phi$, when provided with paramters $\phi$, defines the initial value of the system $x\left(t_0\right) = g_\phi(t_0)$. In order to solve the neural ODE/CDE numerically, we are required to: 
\begin{enumerate}
    \item \textit{Train $g_\phi$ to predict the initial value of the system.} This requires the use of a loss function to train the neural network $g_\phi$, providing the parameters required to accurately predict the initial value of the system. 
    \item \textit{Train $f_\theta$ to provide the parameters of the neural ODE/CDE.} Similar to the prior step, this requires a loss function to train the neural network $f_\theta$, providing the parameters required to accurately state the specific ODE in question. Once the parameters have been approximated, we are left with a standard ODE problem.
    \item \textit{Solve the ODE Problem.} As most ODEs do not have analytical solutions, we make use of numerical ODE solvers to approximate the solution of the system.
\end{enumerate}

This section aims to define and discuss the methods and techniques required to conduct such numerical analysis on neural ODEs/CDEs. In particular, the basic ideas of loss functions, gradient descent and automatic differentiation are introduced here in Section 4.1. Sections 4.2 and 4.3 cover the methods used to train the relevant neural networks, and finally Section 4.4 discusses several numerical methods of solving the eventual ODEs after training. \textcolor{red}{edit section numbering if it changes. do this at the end when all has been confirmed}

\subsubsection{Loss Functions}
points to cover:
\begin{itemize}
    \item why we need loss functions
    \item definition of loss function
    \item how to choose loss functions
    \item basic examples
    \item what to do with loss functions?
\end{itemize}

\subsubsection{Gradient Descent and Applications}
points to cover:
\begin{itemize}
    \item motivation for gradient descent
    \item basic gradient descent and possible issues
    \item stochastic gradient descent - costly calculations
    \item adaptive gradient techniques - RMSProp, ADAM
    \item when to use what method for training
\end{itemize}

\subsubsection{Automatic Differentiation}
points to cover:
\begin{itemize}
    \item motivation behind AD
    \item starting with dual numbers
    \item extending dual numbers to higher dimensions
    \item extending dual numbers to multivariable contexts (taylor series)
    \item AD in general scenarios: chain rule
    \item julia packages implementing AD
\end{itemize}
\textcolor{red}{might be useful to move this to 3.2 instead, since the ideas in AD extend into backpropagation. but honestly it doesnt really matter since they're next to each other.}

\subsection{Backpropagation}

\subsection{log ODE Method}

\subsection{Numerical ODE Solvers}
Upon completion of training of the neural networks (where we have derived the learned parameters $\theta$, $\phi$), all that remains is to solve the subsequent ODE numerically. This can be done in a number of methods, which are generally known as the \textit{Runge-Kutta} methods.

\subsubsection{Euler's Method}
points to cover:
\begin{itemize}
    \item motivation for euler's method
    \item definition of euler's method
    \item proof of euler's method
    \item limitations of euler's method
    \item (maybe an implementation of euler's method? but its not going to be used anyway. see how)
\end{itemize}

\subsubsection{Runge-Kutta Methods}
points to cover:
\begin{itemize}
    \item general runge-kutta methods definition (including matrix representation)
    \item euler's method is a runge-kutta method (1st order)
    \item an example: RK4 (basic? proof and full extension of definition)
    \item actual runge-kutta methods used in julia packages - 5th orders and above  
    \item a short comment on what makes a good method for solving ODEs
\end{itemize}

\section{Application: TBC}

\section{Conclusion}
\textcolor{red}{The conclusion section is required but the previous sections (background, methods, results and discussion) are just examples of sections which may be useful.}

\section*{Acknowledgments}
\addcontentsline{toc}{section}{Acknowledgement}
\textcolor{red}{Comment this out if not needed.}

\appendix

\section{First appendix}
\label{sec:appendix1}

\section{Second appendix}
\label{sec:appendix2}

\bibliography{bibliography.bib}
\end{document}