{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06079be-4ef4-4b6a-8bd9-cc075e2bc4e7",
   "metadata": {},
   "source": [
    "## 1.Inspiration(ResNet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8639c-4f9c-4c2a-a00a-e8f32d86fb5e",
   "metadata": {},
   "source": [
    "The method of neural ODEs (neural ordinary differential equations) was first proposed in a 2018 paper titled \"Neural Ordinary Differential Equations\" This paper won the Best Paper Award at NeurIPS that same year. The inspiration for neural ODEs came from observing a specific neural network model called the residual neural network (ResNet). This model was introduced by a research team at Microsoft in 2015. Unlike traditional neural networks, ResNet incorporates residual connections by adding a residual term to the output of each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57f5bb-1fe5-48bf-a47c-aabd41a018eb",
   "metadata": {},
   "source": [
    "$$\n",
    "h_{t+1} = h_t + ReLU(W_t * h_t + b_t)\\tag{1}\n",
    "$$\n",
    "$$\n",
    "h_{t+1} = h_t + f(h_t, θ_t)\\tag{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf18dfa-0a3b-412e-96c8-e411e1099fab",
   "metadata": {},
   "source": [
    "Here, the second term in equation $(1)$ is in the form of a typical neural network. To get the state at layer $t+1$, we perform calculation using the current state $h_t$, the weight matrix $W_t$ and bias vector $b_t$  at layer $t$, and a non-linear activation function $ReLU$. The first term of $(1)$, $h_t$ is the residual term, representing the identity of the hidden state at layer $t$.\n",
    "We can write equation $(1)$ in the form of equation $(2)$, where $f$ is a function that depends on the state at layer $t$ and some parameters related to this layer. Then, by transforming equation $(2)$ we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aef3e5-4d2b-4a1e-90c0-55b9d341fb8b",
   "metadata": {},
   "source": [
    "$$\n",
    "h_{t+1} - h_t = f(h_t, θ_t)\n",
    "$$\n",
    "$$\n",
    "\\frac{h_{t+1} - h_t }{1}= f(h_t, θ_t)\n",
    "$$\n",
    "$$\n",
    "\\frac{h_{t+\\Delta t} - h_t }{\\Delta t}\\Bigg|_{\\Delta t=1}= f(h_t, θ_t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4623169e-4274-428c-860d-32cf0cadb397",
   "metadata": {},
   "source": [
    "Such a form inspires us to make $\\Delta t$ infinitesimally small, allowing us to transform this discrete form into a continuous one:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a62dd-e136-43f2-9e60-faf198806919",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lim_{\\Delta t\\to 0}\\frac{h_{t+\\Delta t} - h_t }{\\Delta t}= f(h_t, θ_t,t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e2869-6ed1-4688-bef2-9f74398a4d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7347b-1250-4e98-bc3a-5fdf8ec3079e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
