{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a simple neural network that performs regression based on $y = \\sin x$, using the package Lux.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lux, Random, Optimization, OptimizationOptimisers,\n",
    "      ComponentArrays, Zygote, Plots, LinearAlgebra\n",
    "x = range(-pi, pi; length = 100)\n",
    "y = sin.(x)\n",
    "model = Chain(\n",
    "    Dense(1 => 10, relu),\n",
    "    Dense(10 => 10, relu),\n",
    "    Dense(10 => 1)\n",
    ")\n",
    "function regression_loss(ps, (model, st, (x, y)))\n",
    "    return norm(vec(model(x', ps, st)[1]) - y)\n",
    "end\n",
    "ps, st = Lux.setup(MersenneTwister(), model)\n",
    "prob = OptimizationProblem(OptimizationFunction(regression_loss,\n",
    "       Optimization.AutoZygote()), ComponentArray(ps), (model, st, (x, y)))\n",
    "ret = solve(prob, Adam(0.03), maxiters = 250)\n",
    "plot(x, y, label = \"True\")\n",
    "plot!(x, vec(model(x', ret.u, st)[1]), label = \"Predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider another simple neural network that does number recognition based on the MNIST dataset, using another package FLux.jl.\n",
    "\n",
    "[Reference: https://github.com/piotrek124-1/Simple_MNIST_Julia/tree/main]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, MLDatasets\n",
    "\n",
    "# Import the MNIST dataset\n",
    "x_train, y_train = MLDatasets.MNIST.traindata(Float32)\n",
    "x_test, y_test = MLDatasets.MNIST.testdata(Float32)\n",
    "\n",
    "# Flatten the images\n",
    "x_train_flat = Flux.flatten(x_train)\n",
    "x_test_flat = Flux.flatten(x_test)\n",
    "\n",
    "# Use one-hot encoding for the labels\n",
    "y_train_oh = Flux.onehotbatch(y_train, 0:9)\n",
    "\n",
    "# Define a neural network model\n",
    "model = Chain(\n",
    "    Dense(28*28, 196, relu),\n",
    "    Dense(196, 49, relu),\n",
    "    Dense(49, 10)\n",
    ")\n",
    "\n",
    "# Define the loss function based on cross entropy\n",
    "loss(x, y) = Flux.Losses.logitcrossentropy(model(x), y)\n",
    "\n",
    "# Train the neural network\n",
    "dataset = [(x_train_flat, y_train_oh)]\n",
    "for epoch in 1:25\n",
    "    Flux.train!(loss, Flux.params(model), dataset, Adam(0.003))\n",
    "end\n",
    "\n",
    "# Print the test accuracy\n",
    "sum(Flux.onecold(model(x_test_flat)) .== (y_test .+ 1)) / length(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
